{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(lines):\n",
    "    lines = lines.replace('\\r\\n',' ')\n",
    "    lines = lines.replace(':',\" \")\n",
    "    lines = lines.replace(';',\" \")\n",
    "    lines = lines.replace(\"'\",\"\")\n",
    "    lines = lines.replace('\"',\"\")\n",
    "    lines = lines.replace('-',\" \")\n",
    "    lines = lines.replace(')',\" \")\n",
    "    lines = lines.replace('(',\" \")\n",
    "    lines = lines.replace('?',\".\")\n",
    "    lines = lines.replace('!',\".\")\n",
    "    lines = lines.replace('_',\" \")\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = 'alice.txt'\n",
    "lines = open(file_name).read()\n",
    "lines = preprocessing(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = [i.replace('.',\"\") for i in sentences if len(i.split())>=2]\n",
    "words=[]\n",
    "words = [words + (nltk.word_tokenize(i)) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sentences = [\"<s> \"+i +\" </s>\" for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I wonder how many miles Ive fallen by this time </s>\n"
     ]
    }
   ],
   "source": [
    "print (tagged_sentences[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = len(sentences)\n",
    "train_data = tagged_sentences[:int(l*.8)]\n",
    "test_data = tagged_sentences[int(l*.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_lst=[]\n",
    "for i in train_data:\n",
    "    n = 1\n",
    "    grams= ngrams(i.split(), n)\n",
    "    for i in grams:\n",
    "        unigram_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_ctr = Counter(unigram_lst)\n",
    "s = sum(unigram_ctr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_mle={}\n",
    "for i in unigram_ctr:\n",
    "    unigram_mle[i] = unigram_ctr[i]*1.0/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unigram_sentence_probability(sentence,unigram_mle):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        p=1\n",
    "        sentence = preprocessing(sentence)\n",
    "        sentence = \"<s> \"+sentence+\" </s>\"\n",
    "        keys =unigram_mle.keys()\n",
    "        for i in sentence.split():\n",
    "            if (i,) in keys:\n",
    "                p=p*unigram_mle[(i,)]\n",
    "            else:\n",
    "                return 0\n",
    "        return math.log(p)\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def unigram_sentence_generator(unigram_mle):\n",
    "    keys = np.array(unigram_mle.keys())\n",
    "    vals = np.array(unigram_mle.values())\n",
    "    sampled_word = keys[np.random.multinomial(1,vals)==1][0][0]\n",
    "    s=''+sampled_word\n",
    "    cnt=0\n",
    "    while True:\n",
    "        sampled_word = keys[np.random.multinomial(1,vals)==1][0][0]\n",
    "        if sampled_word==\"</s>\":\n",
    "            break\n",
    "        s=s+\" \"+sampled_word\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.04552361263259"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sentence_probability('I am rabbit',unigram_mle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unigram_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "</s> the smiling <s> would it not not but and with now quite this last it Such each hurried\n",
      "\n",
      "the the <s> over a tone her sat riddle Thank they on said ever very and found said voice, she to had and Now, course with no low The its irons\n",
      "\n",
      "and Therefore yourself And on let some Shed her It was argument but head see, out <s> for large all\n",
      "\n",
      "least WAISTCOAT <s> Always you leaves, little Do with <s> Mabel was was upon baby argument is, LOVE and had HIM very by you I\n",
      "\n",
      "earth house the processions you their never <s> looked and the she and she be Alice honour\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sent = unigram_sentence_generator(unigram_mle)\n",
    "    print (\"\\n\"+sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_lst=[]\n",
    "for i in train_data:\n",
    "    n = 2\n",
    "    grams= ngrams(i.split(), n)\n",
    "    for i in grams:\n",
    "        bigram_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_ctr = Counter(bigram_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bigram_sentence_probability(sentence):\n",
    "    try:\n",
    "        p=1\n",
    "        sentence = preprocessing(sentence)\n",
    "        sentence = \"<s> \"+sentence+\" </s>\"\n",
    "        keys =bigram_ctr.keys()\n",
    "        p = p*unigram_mle[('<s>',)]\n",
    "        prev_word = '<s>'\n",
    "        for i in sentence.split()[1:]:\n",
    "\n",
    "            if (prev_word,) in unigram_ctr and (prev_word,i) in bigram_ctr:\n",
    "                p = p*bigram_ctr[(prev_word,i)]/unigram_ctr[(prev_word,)]\n",
    "                prev_word = i\n",
    "            else:\n",
    "                return 0\n",
    "        return math.log(p)\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def sample_word_bigram(prev_word):\n",
    "    possible_word_probability = np.array([[i[1],bigram_ctr[i]*1.0/unigram_ctr[(prev_word,)]] for i in bigram_ctr.keys() if i[0]==prev_word])\n",
    "    vals = possible_word_probability[:,1].astype(float)\n",
    "    keys = possible_word_probability[:,0]\n",
    "    sampled_word = keys[np.random.multinomial(1,vals)==1]\n",
    "    return sampled_word[0]\n",
    "\n",
    "def bigram_sentence_generator():\n",
    "    prev_word = '<s>'\n",
    "    sampled_word = sample_word_bigram(prev_word)\n",
    "    prev_word = sampled_word\n",
    "    s=\"\"\n",
    "    while sampled_word!='</s>':\n",
    "        prev_word = sampled_word\n",
    "        s=s+\" \"+sampled_word\n",
    "        sampled_word = sample_word_bigram(prev_word)\n",
    "       \n",
    "    return s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.964102681360815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_sentence_probability('I want to')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_mle={}\n",
    "for i in bigram_ctr:\n",
    "    bigram_mle[i] = bigram_ctr[i]*1.0/unigram_ctr[(i[0],)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bigram_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " However, the Duchess\n",
      "\n",
      " The fourth\n",
      "\n",
      " Dinah was too late to find her ear, and she had been changed for I he cant help me\n",
      "\n",
      " Come, my throat\n",
      "\n",
      " Oh dear, and dishes\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sent = bigram_sentence_generator()\n",
    "    print (\"\\n\"+sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_lst=[]\n",
    "for i in train_data:\n",
    "    n = 3\n",
    "    grams= ngrams(i.split(), n)\n",
    "    for i in grams:\n",
    "        trigram_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_ctr = Counter(trigram_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigram_sentence_probability(sentence):\n",
    "    try:\n",
    "        p=1\n",
    "        sentence = preprocessing(sentence)\n",
    "        sentence = \"<s> \"+sentence+\" </s>\"\n",
    "        keys=trigram_ctr.keys()\n",
    "        p = p*unigram_mle[('<s>',)]\n",
    "        prev_word_1 = '<s>'\n",
    "        p = p * bigram_ctr[(prev_word_1,sentence.split()[1])]/unigram_ctr[(prev_word_1,)]\n",
    "        prev_word_2 = sentence.split()[1]\n",
    "        for i in sentence.split()[2:]:\n",
    "            #print ((prev_word_1,prev_word_2,i),p)\n",
    "            if (prev_word_1,prev_word_2) in bigram_ctr and (prev_word_1,prev_word_2,i) in trigram_ctr:\n",
    "                p = p*trigram_ctr[(prev_word_1,prev_word_2,i)]/bigram_ctr[(prev_word_1,prev_word_2)]\n",
    "\n",
    "                prev_word_1 = prev_word_2\n",
    "                prev_word_2 = i\n",
    "\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        return math.log(p)\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def trigram_sampler(prev_word_1,prev_word_2):\n",
    "    possible_words = np.array([[i[2],trigram_ctr[i]*1.0/bigram_ctr[(i[0],i[1])]] for i in trigram_ctr.keys() if (i[0]==prev_word_1 and i[1]==prev_word_2)])\n",
    "    keys = possible_words[:,0]\n",
    "    vals = possible_words[:,1].astype(float)\n",
    "    sampled_word = keys[np.random.multinomial(1,vals)==1]\n",
    "    return sampled_word[0]\n",
    "    \n",
    "def trigram_sentence_generator():\n",
    "    prev_word_1 = \"<s>\"\n",
    "    prev_word_2 = sample_word_bigram(prev_word_1)\n",
    "    sampled_word = trigram_sampler(prev_word_1,prev_word_2)\n",
    "    s=\"\"+prev_word_2\n",
    "    while sampled_word!='</s>':\n",
    "        s = s+\" \"+ sampled_word\n",
    "        prev_word_1 = prev_word_2\n",
    "        prev_word_2 = sampled_word\n",
    "        sampled_word = trigram_sampler(prev_word_1,prev_word_2)\n",
    "        \n",
    "    return s\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trigram MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_mle={}\n",
    "for i in trigram_ctr:\n",
    "    trigram_mle[i] = trigram_ctr[i]*1.0/bigram_ctr[(i[0],i[1])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=0\n",
    "for i in trigram_mle:\n",
    "    if i[0]=='had' and i[1]=='any':\n",
    "        s=s+trigram_mle[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trigram_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, Serpent\n",
      "\n",
      "said the Hatter grumbled you shouldnt talk, said the last time she heard it say to itself, Oh dear\n",
      "\n",
      "Then they both sat silent and looked at them with the grin, which remained some time with one elbow against the door, staring stupidly up into a sort of lullaby to it\n",
      "\n",
      "I dare say youre wondering why I dont want to be found all she could guess, she was appealed to by the Hatter, it woke up again\n",
      "\n",
      "Who ARE you to death\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sent = trigram_sentence_generator()\n",
    "    print (sent+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quadragram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quadgram_lst=[]\n",
    "for i in train_data:\n",
    "    n = 4\n",
    "    grams= ngrams(i.split(), n)\n",
    "    for i in grams:\n",
    "        quadgram_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quadgram_ctr = Counter(quadgram_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quadgram_sentence_probability(sentence):\n",
    "    try:\n",
    "        prev_word_1 = '<s>'\n",
    "        sentence = '<s> '+sentence+\" </s>\"\n",
    "        p = 1\n",
    "        p = p*unigram_mle[(prev_word_1,)]\n",
    "        prev_word_2 = sentence.split()[1]\n",
    "        prev_word_3 = sentence.split()[2]\n",
    "        p = p * bigram_ctr[(prev_word_1,prev_word_2)]*1.0/unigram_ctr[(prev_word_1,)]\n",
    "        p = p * trigram_ctr[(prev_word_1,prev_word_2,prev_word_3)]*1.0 /bigram_ctr[(prev_word_1,prev_word_2)]\n",
    "\n",
    "\n",
    "\n",
    "        for i in sentence.split()[3:]:\n",
    "            #print (prev_word_1,prev_word_2,prev_word_3,i,p,quadgram_ctr[(prev_word_1,prev_word_2,prev_word_3,i)])\n",
    "            p = p*quadgram_ctr[(prev_word_1,prev_word_2,prev_word_3,i)]*1.0/trigram_ctr[(prev_word_1,prev_word_2,prev_word_3)]\n",
    "            prev_word_1 = prev_word_2\n",
    "            prev_word_2 = prev_word_3\n",
    "            prev_word_3 = i\n",
    "        return math.log(p)\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    \n",
    "def quadgram_word_sampler(prev_word_1,prev_word_2,prev_word_3):\n",
    "    possible_words = np.array([[i[3],quadgram_ctr[i]*1.0/trigram_ctr[(i[0],i[1],i[2])]] for i in quadgram_ctr.keys() if (i[0]==prev_word_1 and i[1]==prev_word_2 and i[2]==prev_word_3)])\n",
    "    \n",
    "    \n",
    "    keys = possible_words[:,0]\n",
    "    vals = possible_words[:,1].astype(float)\n",
    "    sampled_word = keys[np.random.multinomial(1,vals)==1]\n",
    " \n",
    "    return sampled_word[0]\n",
    "\n",
    "\n",
    "def quadgram_word_generator():\n",
    "    s=\"\"\n",
    "    prev_word_1 = \"<s>\"\n",
    "    prev_word_2 = sample_word_bigram(prev_word_1)\n",
    "    prev_word_3 = trigram_sampler(prev_word_1,prev_word_2)\n",
    "    s= s+prev_word_2 + \" \"+prev_word_3+\" \"\n",
    "    \n",
    "    sampled_word = quadgram_word_sampler(prev_word_1,prev_word_2,prev_word_3)\n",
    "    \n",
    "    while sampled_word!=\"</s>\":\n",
    "        s= s+\" \"+sampled_word\n",
    "        prev_word_1 = prev_word_2\n",
    "        prev_word_2 = prev_word_3\n",
    "        prev_word_3 = sampled_word\n",
    "        sampled_word = quadgram_word_sampler(prev_word_1,prev_word_2,prev_word_3)\n",
    "    return s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.090464920866276"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadgram_sentence_probability(\"I wonder how many miles Ive fallen by this time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadgram MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadgram_mle={}\n",
    "for i in quadgram_ctr:\n",
    "    quadgram_mle[i] = quadgram_ctr[i]*1.0/trigram_ctr[(i[0],i[1],i[2])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#quadgram_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadgram Sentence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You see  the earth takes twenty four hours to turn round on its axis Talking of axes, said the Duchess, and thats why\n",
      "\n",
      "Dont go  splashing paint over me like that\n",
      "\n",
      "While she  was looking at the house, and the March Hare\n",
      "\n",
      "I wish  you were down here with me\n",
      "\n",
      "This time  Alice waited patiently until it chose to speak again\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sent = quadgram_word_generator()\n",
    "    print (sent+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-74.84532521363464"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sentence_probability(\"I wonder how many miles Ive fallen by this time\",unigram_mle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.631919676231004"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_sentence_probability(\"I wonder how many miles Ive fallen by this time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.453921974545585"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_sentence_probability(\"I wonder how many miles Ive fallen by this time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.090464920866276"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadgram_sentence_probability('I wonder how many miles Ive fallen by this time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Quadgram Model is superior compared to the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Possible N-Grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Possible Unigrams are 3201 . Actual Number of Unigrams are 3201\n"
     ]
    }
   ],
   "source": [
    "print (\"The Number of Possible Unigrams are {} . Actual Number of Unigrams are {}\".format(len(unigram_ctr),len(unigram_ctr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Possible Bigrams are 10246401 . Actual Number of Bigrams are 13362\n"
     ]
    }
   ],
   "source": [
    "print (\"The Number of Possible Bigrams are {} . Actual Number of Bigrams are {}\".format(len(unigram_ctr)**2,len(bigram_ctr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Possible Trigrams are 32798729601 . Actual Number of Trigrams are 18779\n"
     ]
    }
   ],
   "source": [
    "print (\"The Number of Possible Trigrams are {} . Actual Number of Trigrams are {}\".format(len(unigram_ctr)**3,len(trigram_ctr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Possible Quadgrams are 104988733452801 . Actual Number of Quadgrams are 19462\n"
     ]
    }
   ],
   "source": [
    "print (\"The Number of Possible Quadgrams are {} . Actual Number of Quadgrams are {}\".format(len(unigram_ctr)**4,len(quadgram_ctr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add one Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_mle={}\n",
    "for i in bigram_ctr:\n",
    "    bigram_mle[i] = bigram_ctr[i]*1.0/unigram_ctr[(i[0],)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bigram_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "bigram_add_one={}\n",
    "for i in unigram_ctr:\n",
    "    for j in unigram_ctr:\n",
    "        if (i[0],j[0]) in bigram_ctr:\n",
    "            bigram_add_one[(i[0],j[0])] = bigram_ctr[(i[0],j[0])]+1\n",
    "        else:\n",
    "            bigram_add_one[(i[0],j[0])] = 1\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_add_one_mle = {}\n",
    "for i in bigram_add_one:\n",
    "    bigram_add_one_mle[i] = bigram_add_one[i]*1.0/(unigram_ctr[(i[0],)]+len(unigram_ctr))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words that were affected drastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How', 'surprised')\n",
      "('Pre Smoothing Probability is ', 0.041666666666666664)\n",
      "('Post Smoothing Probability is ', 0.00062015503875969)\n"
     ]
    }
   ],
   "source": [
    "random.seed(40)\n",
    "word = random.choice(bigram_mle.keys())\n",
    "print (word)\n",
    "print (\"Pre Smoothing Probability is \",bigram_mle[word])\n",
    "print (\"Post Smoothing Probability is \",bigram_add_one_mle[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('then,', 'when')\n",
      "('Pre Smoothing Probability is ', 0.08333333333333333)\n",
      "('Post Smoothing Probability is ', 0.0006224712107065049)\n"
     ]
    }
   ],
   "source": [
    "word = random.choice(bigram_mle.keys())\n",
    "print (word)\n",
    "print (\"Pre Smoothing Probability is \",bigram_mle[word])\n",
    "print (\"Post Smoothing Probability is \",bigram_add_one_mle[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rabbits', 'voice')\n",
      "('Pre Smoothing Probability is ', 0.5)\n",
      "('Post Smoothing Probability is ', 0.00093603744149766)\n"
     ]
    }
   ],
   "source": [
    "random.seed(81)\n",
    "word = random.choice(bigram_mle.keys())\n",
    "print (word)\n",
    "print (\"Pre Smoothing Probability is \",bigram_mle[word])\n",
    "print (\"Post Smoothing Probability is \",bigram_add_one_mle[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_ctr = Counter(bigram_ctr.values())\n",
    "gt_ctr={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    gt_ctr[i] = (i+1)*(original_ctr[i+1])*1.0/(original_ctr[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718266844818\n",
      "0.908536585366\n",
      "1.05586592179\n",
      "1.06896551724\n",
      "0.960784313725\n",
      "1.5145631068\n",
      "1.06060606061\n",
      "2.30612244898\n",
      "-1.96774193548\n",
      "4.17647058824\n"
     ]
    }
   ],
   "source": [
    "for i in gt_ctr:\n",
    "    print (i - gt_ctr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Value of Discounting Factor is close to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Perplexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(2,11):\n",
    "    s=s+gt_ctr[j]*(j-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4731.250137759335"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
